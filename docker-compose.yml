services:
  spark-master:
    build:
      context: .
      dockerfile: docker/Dockerfile-spark
    container_name: spark-master
    environment:
      - SPARK_MODE=master
    env_file:
      - .env
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./scraper:/opt/bitnami/spark/work
      - ./postgresql-42.2.18.jar:/opt/bitnami/spark/jars/postgresql-42.2.18.jar
    networks:
      - spark-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4g

  spark-worker:
    build:
      context: .
      dockerfile: docker/Dockerfile-spark
    environment:
      - SPARK_MODE=worker
    env_file:
      - .env
    volumes:
      - ./scraper:/opt/bitnami/spark/work
      - ./postgresql-42.2.18.jar:/opt/bitnami/spark/jars/postgresql-42.2.18.jar
    networks:
      - spark-network
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          cpus: '2.0'
          memory: 4g

  spark-job:
    build:
      context: .
      dockerfile: docker/Dockerfile-spark
    container_name: spark-job
    volumes:
      - ./spark_jobs:/opt/bitnami/spark/work/spark_jobs
      - ./requirements.txt:/opt/bitnami/spark/work/requirements.txt
      - ./postgresql-42.2.18.jar:/opt/bitnami/spark/jars/postgresql-42.2.18.jar
    command: [
      "spark-submit",
      "--master", "spark://spark-master:7077",
      "--packages", "org.mongodb.spark:mongo-spark-connector_2.12:10.2.1,org.postgresql:postgresql:42.6.0",
      "spark_jobs/preprocess_data.py"
    ]
    depends_on:
      - spark-master
    networks:
      - spark-network

  scraper-seloger:
    build:
      context: .
      dockerfile: docker/Dockerfile.scraper
    env_file:
      - .env
    environment:
      - SPIDER_SCRIPT=run_seloger_spiders.py
    volumes:
      - ./scraper:/opt/bitnami/spark/work
      - ./postgresql-42.2.18.jar:/opt/bitnami/spark/jars/postgresql-42.2.18.jar
    networks:
      - spark-network
    depends_on:
      spark-master:
        condition: service_started
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2g

  scraper-bienici:
    build:
      context: .
      dockerfile: docker/Dockerfile.scraper
    env_file:
      - .env
    environment:
      - SPIDER_SCRIPT=run_bienici_spiders.py
    volumes:
      - ./scraper:/opt/bitnami/spark/work
      - ./postgresql-42.2.18.jar:/opt/bitnami/spark/jars/postgresql-42.2.18.jar
    networks:
      - spark-network
    depends_on:
      spark-master:
        condition: service_started
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2g

  scraper-gouv:
    build:
      context: .
      dockerfile: docker/Dockerfile.scraper
    env_file:
      - .env
    environment:
      - SPIDER_SCRIPT=run_gouv_spiders.py
    volumes:
      - ./scraper:/opt/bitnami/spark/work
      - ./postgresql-42.2.18.jar:/opt/bitnami/spark/jars/postgresql-42.2.18.jar
    networks:
      - spark-network
    depends_on:
      spark-master:
        condition: service_started
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2g

networks:
  spark-network:
    driver: bridge